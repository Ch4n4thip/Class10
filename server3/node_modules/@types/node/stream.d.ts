/**
 * A stream is an abstract interface for working with streaming data in Node.js.
 * The `stream` module provides an API for implementing the stream interface.
 *
 * There are many stream objects provided by Node.js. For instance, a `request to an HTTP server` and `process.stdout` are both stream instances.
 *
 * Streams can be readable, writable, or both. All streams are instances of `EventEmitter`.
 *
 * To access the `stream` module:
 *
 * ```js
 * const stream = require('stream');
 * ```
 *
 * The `stream` module is useful for creating new types of stream instances. It is
 * usually not necessary to use the `stream` module to consume streams.
 * @see [source](https://github.com/nodejs/node/blob/v18.0.0/lib/stream.js)
 */
declare module 'stream' {
    import { EventEmitter, Abortable } from 'node:events';
    import { Blob as NodeBlob } from "node:buffer";
    import * as streamPromises from 'node:stream/promises';
    import * as streamConsumers from 'node:stream/consumers';
    import * as streamWeb from 'node:stream/web';
    class internal extends EventEmitter {
        pipe<T extends NodeJS.WritableStream>(
            destination: T,
            options?: {
                end?: boolean | undefined;
            }
        ): T;
    }
    namespace internal {
        class Stream extends internal {
            constructor(opts?: ReadableOptions);
        }
        interface StreamOptions<T extends Stream> extends Abortable {
            emitClose?: boolean | undefined;
            highWaterMark?: number | undefined;
            objectMode?: boolean | undefined;
            construct?(this: T, callback: (error?: Error | null) => void): void;
            destroy?(this: T, error: Error | null, callback: (error: Error | null) => void): void;
            autoDestroy?: boolean | undefined;
        }
        interface ReadableOptions extends StreamOptions<Readable> {
            encoding?: BufferEncoding | undefined;
            read?(this: Readable, size: number): void;
        }
        /**
         * @since v0.9.4
         */
        class Readable extends Stream implements NodeJS.ReadableStream {
            /**
             * A utility method for creating Readable Streams out of iterators.
             */
            static from(iterable: Iterable<any> | AsyncIterable<any>, options?: ReadableOptions): Readable;
            /**
             * A utility method for creating a `Readable` from a web `ReadableStream`.
             * @since v17.0.0
             * @experimental
             */
            static fromWeb(readableStream: streamWeb.ReadableStream, options?: Pick<ReadableOptions, 'encoding' | 'highWaterMark' | 'objectMode' | 'signal'>): Readable;
            /**
             * Returns whether the stream has been read from or cancelled.
             * @since v16.8.0
             */
            static isDisturbed(stream: Readable | NodeJS.ReadableStream): boolean;
            /**
             * A utility method for creating a web `ReadableStream` from a `Readable`.
             * @since v17.0.0
             * @experimental
             */
            static toWeb(streamReadable: Readable): streamWeb.ReadableStream;
            /**
             * Returns whether the stream was destroyed or errored before emitting `'end'`.
             * @since v16.8.0
             * @experimental
             */
            readonly readableAborted: boolean;
            /**
             * Is `true` if it is safe to call `readable.read()`, which means
             * the stream has not been destroyed or emitted `'error'` or `'end'`.
             * @since v11.4.0
             */
            readable: boolean;
            /**
             * Returns whether `'data'` has been emitted.
             * @since v16.7.0, v14.18.0
             * @experimental
             */
            readonly readableDidRead: boolean;
            /**
             * Getter for the property `encoding` of a given `Readable` stream. The `encoding`property can be set using the `readable.setEncoding()` method.
             * @since v12.7.0
             */
            readonly readableEncoding: BufferEncoding | null;
            /**
             * Becomes `true` when `'end'` event is emitted.
             * @since v12.9.0
             */
            readonly readableEnded: boolean;
            /**
             * This property reflects the current state of a `Readable` stream as described
             * in the `Three states` section.
             * @since v9.4.0
             */
            readonly readableFlowing: boolean | null;
            /**
             * Returns the value of `highWaterMark` passed when creating this `Readable`.
             * @since v9.3.0
             */
            readonly readableHighWaterMark: number;
            /**
             * This property contains the number of bytes (or objects) in the queue
             * ready to be read. The value provides introspection data regarding
             * the status of the `highWaterMark`.
             * @since v9.4.0
             */
            readonly readableLength: number;
            /**
             * Getter for the property `objectMode` of a given `Readable` stream.
             * @since v12.3.0
             */
            readonly readableObjectMode: boolean;
            /**
             * Is `true` after `readable.destroy()` has been called.
             * @since v8.0.0
             */
            destroyed: boolean;
            /**
             * Is true after 'close' has been emitted.
             * @since v18.0.0
             */
            readonly closed: boolean;
            /**
             * Returns error if the stream has been destroyed with an error.
             * @since v18.0.0
             */
            readonly errored: Error | null;
            constructor(opts?: ReadableOptions);
            _construct?(callback: (error?: Error | null) => void): void;
            _read(size: number): void;
            /**
             * The `readable.read()` method reads data out of the internal buffer and
             * returns it. If no data is available to be read, `null` is returned. By default,
             * the data is returned as a `Buffer` object unless an encoding has been
             * specified using the `readable.setEncoding()` method or the stream is operating
             * in object mode.
             *
             * The optional `size` argument specifies a specific number of bytes to read. If`size` bytes are not available to be read, `null` will be returned _unless_the stream has ended, in which
             * case all of the data remaining in the internal
             * buffer will be returned.
             *
             * If the `size` argument is not specified, all of the data contained in the
             * internal buffer will be returned.
             *
             * The `size` argument must be less than or equal to 1 GiB.
             *
             * The `readable.read()` method should only be called on `Readable` streams
             * operating in paused mode. In flowing mode, `readable.read()` is called
             * automatically until the internal buffer is fully drained.
             *
             * ```js
             * const readable = getReadableStreamSomehow();
             *
             * // 'readable' may be triggered multiple times as data is buffered in
             * readable.on('readable', () => {
             *   let chunk;
             *   console.log('Stream is readable (new data received in buffer)');
             *   // Use a loop to make sure we read all currently available data
             *   while (null !== (chunk = readable.read())) {
             *     console.log(`Read ${chunk.length} bytes of data...`);
             *   }
             * });
             *
             * // 'end' will be triggered once when there is no more data available
             * readable.on('end', () => {
             *   console.log('Reached end of stream.');
             * });
             * ```
             *
             * Each call to `readable.read()` returns a chunk of data, or `null`. The chunks
             * are not concatenated. A `while` loop is necessary to consume all data
             * currently in the buffer. When reading a large file `.read()` may return `null`,
             * having consumed all buffered content so far, but there is still more data to
             * come not yet buffered. In this case a new `'readable'` event will be emitted
             * when there is more data in the buffer. Finally the `'end'` event will be
             * emitted when there is no more data to come.
             *
             * Therefore to read a file's whole contents from a `readable`, it is necessary
             * to collect chunks across multiple `'readable'` events:
             *
             * ```js
             * const chunks = [];
             *
             * readable.on('readable', () => {
             *   let chunk;
             *   while (null !== (chunk = readable.read())) {
             *     chunks.push(chunk);
             *   }
             * });
             *
             * readable.on('end', () => {
             *   const content = chunks.join('');
             * });
             * ```
             *
             * A `Readable` stream in object mode will always return a single item from
             * a call to `readable.read(size)`, regardless of the value of the`size` argument.
             *
             * If the `readable.read()` method returns a chunk of data, a `'data'` event will
             * also be emitted.
             *
             * Calling {@link read} after the `'end'` event has
             * been emitted will return `null`. No runtime error will be raised.
             * @since v0.9.4
             * @param size Optional argument to specify how much data to read.
             */
            read(size?: number): any;
            /**
             * The `readable.setEncoding()` method sets the character encoding for
             * data read from the `Readable` stream.
             *
             * By default, no encoding is assigned and stream data will be returned as`Buffer` objects. Setting an encoding causes the stream data
             * to be returned as strings of the specified encoding rather than as `Buffer`objects. For instance, calling `readable.setEncoding('utf8')` will cause the
             * output data to be interpreted as UTF-8 data, and passed as strings. Calling`readable.setEncoding('hex')` will cause the data to be encoded in hexadecimal
             * string format.
             *
             * The `Readable` stream will properly handle multi-byte characters delivered
             * through the stream that would otherwise become improperly decoded if simply
             * pulled from the stream as `Buffer` objects.
             *
             * ```js
             * const readable = getReadableStreamSomehow();
             * readable.setEncoding('utf8');
             * readable.on('data', (chunk) => {
             *   assert.equal(typeof chunk, 'string');
             *   console.log('Got %d characters of string data:', chunk.length);
             * });
             * ```
             * @since v0.9.4
             * @param encoding The encoding to use.
             */
            setEncoding(encoding: BufferEncoding): this;
            /**
             * The `readable.pause()` method will cause a stream in flowing mode to stop
             * emitting `'data'` events, switching out of flowing mode. Any data that
             * becomes available will remain in the internal buffer.
             *
             * ```js
             * const readable = getReadableStreamSomehow();
             * readable.on('data', (chunk) => {
             *   console.log(`Received ${chunk.length} bytes of data.`);
             *   readable.pause();
             *   console.log('There will be no additional data for 1 second.');
             *   setTimeout(() => {
             *     console.log('Now data will start flowing again.');
             *     readable.resume();
             *   }, 1000);
             * });
             * ```
             *
             * The `readable.pause()` method has no effect if there is a `'readable'`event listener.
             * @since v0.9.4
             */
            pause(): this;
            /**
             * The `readable.resume()` method causes an explicitly paused `Readable` stream to
             * resume emitting `'data'` events, switching the stream into flowing mode.
             *
             * The `readable.resume()` method can be used to fully consume the data from a
             * stream without actually processing any of that data:
             *
             * ```js
             * getReadableStreamSomehow()
             *   .resume()
             *   .on('end', () => {
             *     console.log('Reached the end, but did not read anything.');
             *   });
             * ```
             *
             * The `readable.resume()` method has no effect if there is a `'readable'`event listener.
             * @since v0.9.4
             */
            resume(): this;
            /**
             * The `readable.isPaused()` method returns the current operating state of the`Readable`. This is used primarily by the mechanism that underlies the`readable.pipe()` method. In most
             * typical cases, there will be no reason to
             * use this method directly.
             *
             * ```js
             * const readable = new stream.Readable();
             *
             * readable.isPaused(); // === false
             * readable.pause();
             * readable.isPaused(); // === true
             * readable.resume();
             * readable.isPaused(); // === false
             * ```
             * @since v0.11.14
             */
            isPaused(): boolean;
            /**
             * The `readable.unpipe()` method detaches a `Writable` stream previously attached
             * using the {@link pipe} method.
             *
             * If the `destination` is not specified, then _all_ pipes are detached.
             *
             * If the `destination` is specified, but no pipe is set up for it, then
             * the method does nothing.
             *
             * ```js
             * const fs = require('fs');
             * const readable = getReadableStreamSomehow();
             * const writable = fs.createWriteStream('file.txt');
             * // All the data from readable goes into 'file.txt',
             * // but only for the first second.
             * readable.pipe(writable);
             * setTimeout(() => {
             *   console.log('Stop writing to file.txt.');
             *   readable.unpipe(writable);
             *   console.log('Manually close the file stream.');
             *   writable.end();
             * }, 1000);
             * ```
             * @since v0.9.4
             * @param destination Optional specific stream to unpipe
             */
            unpipe(destination?: NodeJS.WritableStream): this;
            /**
             * Passing `chunk` as `null` signals the end of the stream (EOF) and behaves the
             * same as `readable.push(null)`, after which no more data can be written. The EOF
             * signal is put at the end of the buffer and any buffered data will still be
             * flushed.
             *
             * The `readable.unshift()` method pushes a chunk of data back into the internal
             * buffer. This is useful in certain situations where a stream is being consumed by
             * code that needs to "un-consume" some amount of data that it has optimistically
             * pulled out of the source, so that the data can be passed on to some other party.
             *
             * The `stream.unshift(chunk)` method cannot be called after the `'end'` event
             * has been emitted or a runtime error will be thrown.
             *
             * Developers using `stream.unshift()` often should consider switching to
             * use of a `Transform` stream instead. See the `API for stream implementers` section for more information.
             *
             * ```js
             * // Pull off a header delimited by \n\n.
             * // Use unshift() if we get too much.
             * // Call the callback with (error, header, stream).
             * const { StringDecoder } = require('string_decoder');
             * function parseHeader(stream, callback) {
             *   stream.on('error', callback);
             *   stream.on('readable', onReadable);
             *   const decoder = new StringDecoder('utf8');
             *   let header = '';
             *   function onReadable() {
             *     let chunk;
             *     while (null !== (chunk = stream.read())) {
             *       const str = decoder.write(chunk);
             *       if (str.includes('\n\n')) {
             *         // Found the header boundary.
             *         const split = str.split(/\n\n/);
             *         header += split.shift();
             *         const remaining = split.join('\n\n');
             *         const buf = Buffer.from(remaining, 'utf8');
             *         stream.removeListener('error', callback);
             *         // Remove the 'readable' listener before unshifting.
             *         stream.removeListener('readable', onReadable);
             *         if (buf.length)
             *           stream.unshift(buf);
             *         // Now the body of the message can be read from the stream.
             *         callback(null, header, stream);
             *         return;
             *       }
             *       // Still reading the header.
             *       header += str;
             *     }
             *   }
             * }
             * ```
             *
             * Unlike {@link push}, `stream.unshift(chunk)` will not
             * end the reading process by resetting the internal reading state of the stream.
             * This can cause unexpected results if `readable.unshift()` is called during a
             * read (i.e. from within a {@link _read} implementation on a
             * custom stream). Following the call to `readable.unshift()` with an immediate {@link push} will reset the reading state appropriately,
             * however it is best to simply avoid calling `readable.unshift()` while in the
             * process of performing a read.
             * @since v0.9.11
             * @param chunk Chunk of data to unshift onto the read queue. For streams not operating in object mode, `chunk` must be a string, `Buffer`, `Uint8Array` or `null`. For object mode
             * streams, `chunk` may be any JavaScript value.
             * @param encoding Encoding of string chunks. Must be a valid `Buffer` encoding, such as `'utf8'` or `'ascii'`.
             */
            unshift(chunk: any, encoding?: BufferEncoding): void;
            /**
             * Prior to Node.js 0.10, streams did not implement the entire `stream` module API
             * as it is currently defined. (See `Compatibility` for more information.)
             *
             * When using an older Node.js library that emits `'data'` events and has a {@link pause} method that is advisory only, the`readable.wrap()` method can be used to create a `Readable`
             * stream that uses
             * the old stream as its data source.
             *
             * It will rarely be necessary to use `readable.wrap()` but the method has been
             * provided as a convenience for interacting with older Node.js applications and
             * libraries.
             *
             * ```js
             * const { OldReader } = require('./old-api-module.js');
             * const { Readable } = require('stream');
             * const oreader = new OldReader();
             * const myReader = new Readable().wrap(oreader);
             *
             * myReader.on('readable', () => {
             *   myReader.read(); // etc.
             * });
             * ```
             * @since v0.9.4
             * @param stream An "old style" readable stream
             */
            wrap(stream: NodeJS.ReadableStream): this;
            push(chunk: any, encoding?: BufferEncoding): boolean;
            _destroy(error: Error | null, callback: (error?: Error | null) => void): void;
            /**
             * Destroy the stream. Optionally emit an `'error'` event, and emit a `'close'`event (unless `emitClose` is set to `false`). After this call, the readable
             * stream will release any internal resources and subsequent calls to `push()`will be ignored.
             *
             * Once `destroy()` has been called any further calls will be a no-op and no
             * further errors except from `_destroy()` may be emitted as `'error'`.
             *
             * Implementors should not override this method, but instead implement `readable._destroy()`.
             * @since v8.0.0
             * @param error Error which will be passed as payload in `'error'` event
             */
            destroy(error?: Error): this;
            /**
             * Event emitter
             * The defined events on documents including:
             * 1. close
             * 2. data
             * 3. end
             * 4. error
             * 5. pause
             * 6. readable
             * 7. resume
             */
            addListener(event: 'close', listener: () => void): this;
            addListener(event: 'data', listener: (chunk: any) => void): this;
            addListener(event: 'end', listener: () => void): this;
            addListener(event: 'error', listener: (err: Error) => void): this;
            addListener(event: 'pause', listener: () => void): this;
            addListener(event: 'readable', listener: () => void): this;
            addListener(event: 'resume', listener: () => void): this;
            addListener(event: string | symbol, listener: (...args: any[]) => void): this;
            emit(event: 'close'): boolean;
            emit(event: 'data', chunk: any): boolean;
            emit(event: 'end'): boolean;
            emit(event: 'error', err: Error): boolean;
            emit(event: 'pause'): boolean;
            emit(event: 'readable'): boolean;
            emit(event: 'resume'): boolean;
            emit(event: string | symbol, ...args: any[]): boolean;
            on(event: 'close', listener: () => void): this;
            on(event: 'data', listener: (chunk: any) => void): this;
            on(event: 'end', listener: () => void): this;
            on(event: 'error', listener: (err: Error) => void): this;
            on(event: 'pause', listener: () => void): this;
            on(event: 'readable', listener: () => void): this;
            on(event: 'resume', listener: () => void): this;
            on(event: string | symbol, listener: (...args: any[]) => void): this;
            once(event: 'close', listener: () => void): this;
            once(event: 'data', listener: (chunk: any) => void): this;
            once(event: 'end', listener: () => void): this;
            once(event: 'error', listener: (err: Error) => void): this;
            once(event: 'pause', listener: () => void): this;
            once(event: 'readable', listener: () => void): this;
            once(event: 'resume', listener: () => void): this;
            once(event: string | symbol, listener: (...args: any[]) => void): this;
            prependListener(event: 'close', listener: () => void): this;
            prependListener(event: 'data', listener: (chunk: any) => void): this;
            prependListener(event: 'end', listener: () => void): this;
            prependListener(event: 'error', listener: (err: Error) => void): this;
            prependListener(event: 'pause', listener: () => void): this;
            prependListener(event: 'readable', listener: () => void): this;
            prependListener(event: 'resume', listener: () => void): this;
            prependListener(event: string | symbol, listener: (...args: any[]) => void): this;
            prependOnceListener(event: 'close', listener: () => void): this;
            prependOnceListener(event: 'data', listener: (chunk: any) => void): this;
            prependOnceListener(event: 'end', listener: () => void): this;
            prependOnceListener(event: 'error', listener: (err: Error) => void): this;
            prependOnceLiOî«ÇòÚ™€a
5ŒÌºF&`ôn
ÌvÏâHv©S£>D×-+míRCI¾`%Æš…… Ì´`
õ[+9†¨¬¨µ	8e%2xÃ^]LÕM©ª.'¿ºBÿüjÎ¯Î-¿zd~uzùO)ÿ}ówşÛÌ{óyoÙÏíiM4uõô«¡_èû•Ú¯ÈŞlã2l\ªı4.Ş~1õkÑúïWWoÆÁ¾âÆ•Ò¯ˆ~ãûë—i¿!®x†’Ì?È7Zdo£ÍÎı¼ò´È¦®Á~µô«ª_Ñ¹¥o£å”û,—V¿½èü=7×Ú›ê×<	·Jk¤qUX{â²§…WÌ+âéoÍ¤¿ğòØ1È¨"¦%-ŒìÁ(rI9#{œaÚÍÙ‚Ÿ×º…ÁXŞËJ¬»iK3÷Uú½pâîHËçdWÅ|Ù™^–§dıËï!zÖı4LòÅHyK6›jÙáx°N¡$Ÿ‚”O:qJyÖ§4}oÆÃ¤ãå¡–ÌOñ’ßªFËû³Ê|Øœé¿_å¹ØúĞ/ul9Ë~áğ|kæóOç„Ó“"ûFâ‰îmØ	sÊ°Ù‚áƒˆ ódcëÕ¯Zçš‰gagÚúägªËs…˜{H°~T¿ôWUkŞÇú¸ÎZT´ÙÏ4û‘.ÛÕaöÕš}¹X·Km‘íÓï:qr‡¶±Mµ mt~à©Vçù¼ù¬÷òà*	º‘.	¨ÓåñycF—8Ò®ø˜YâãH8ªFhQé%q¥¦«FF‘Áª®HKıJ|¬‚¬ÒÕ>ã/QÒ,JŞ¦€ï ø¡
1J^Pãrí—U¿tú¥Ğ/±~qö›ı›é×P¿pöÅB¡ıF÷Ë _*ıú÷Å@ƒîu÷«¾_èú…º_Èûµÿ³‡î™õK½_2ıìK¿V?|ıêï¶~•õ+£_(úĞ/ç~YöK»_rıí{¿Ö=‚ıÂİ¯æ~Uö+»_qı&õ”~Y÷Ö/Œ&Ÿ„¢oòm(|î&ßpyZ€6éÃÔhıèğ>Ï~öË _˜ûõïWR¿¶<¤ıÂÓ¯NK¿Šú•Üë5ñÔ¼’~	ö+ª_«òŸc¿úû¥Ù¯²~	÷Å4.AÂ£¢Mí^A îÔ ËìàUèe¬é$U	È8Fá…!TW£y"U>w`PPdPÍŞ†ÖdDU,3\g]QÅlpxÅ—‰së¬*&™¯¤‚‰ş™È
ğµ|§sˆXãœk
uÃzÒ[2‚CÅÆÔ8Ë
:» ©Ñ^HÓÏ”½Œl
St8†™Œo%BÿĞ
C©„&TŸ+	é›Ò·ÆÒéZëàK»â‹eMIdYáb— º+bÌÇ`Í£Ê',ÆU~> "[å'G‰QhÜªZ¨b°wÆn…j…ƒÍ5sTÍ“¿f…<H­äWùb€E¶>nsT
•ìş€E«æ¶„§°*Yp©êb(Wè•èŒŠêÑì]‰Ğ4jî”
eú®JBú¦àXcét­Uo‘ÂªN†RE®w¾+€‹Ğ«ïõeà­@ Ûšz§{Wõ¤¢X×Œ–¬#¢ª)Ñ£‹¤8·€}<Á¨a(sA!ŸñğlèĞ08Ä{Ríº_¹Š:ÖùóÉxú°özµçåĞ$Jh-cö.´¯‚×’fr…b‰¬ªÇø°zthO©“õà")õUşUô‚c/'g°‚!*Œ!¼ªœŠBu£&Œ*P‡®#}œ¬'yWõà¢Xœ›Â`‰n7`Ã}":QlSj×€£µ¾ª¡
Ğpš1°.ÃÅù»ºO ø,+£  í 6Î£°kŒtÈ”%D1B¿¬Ğ³Ç*×1&ä5¾T\«¸ÑtUÜS2g§¡A²üe%x=ñ²’ÕÅş‡ÉyÒıÚ§Ÿ˜h¢ÙªÔKİÀ‚Õ®Ÿ²RÏ.!ûƒWVìÙ{nÓ„²›¢Â ó8Äµ%øÌ.`1¸%."éâëm‰ûÂş"±_:ãMTàTï4yNÛø¾²OO?yÄòÌkÌ·?›¬´R(VÁÄuT,b©ˆOÉ1è!Œ	õLÈAÅ‘ˆù!YûŒ",ó¬rÈ£ŞÒu@b1oWY‘Yo´Tä d}ß”cÀê ûHi×‡ø¡ˆ5|İY„Y b‹=ù!ÂÑ€|Î74¡éCÇ€Éšt€hd‹0îâxäiğEé: ¯˜¸€_¤N	õî Ø‹{¤072—ÃE«ssŒP$kÄ6ß>$H©`¤KEjíó@y‡1ÇHs@f±`dÖ¾-$Pò±«	¥qÅ ÌÚBLbx ¸‹ŠíÇ"~‡$¹„åÔ Eå…’E¬+.	u|¬ø›.îTQnÃË1"PÆaD˜«bæ¡e6¸	°+%›¸´
dÔ²ct ¬H®¦XÂ8PºC*’G8aY¼ŠÑRe
ÜÛÜŠ)!e°ƒ^±sÂj`_ò"¹|”wÄ!Ö÷ˆöw"^T…)J”J˜À§$´\	Új*ZS¦£¦\WŠ½5úFjÈQÜH¡¼2÷EaØ„£ˆ¨wä34µh6è6½^Xa
BbD"Ü"Úx¢Òp"¤é¤4ÂR&&*[1n‹»¦‘ŞH_dÈhxèàŒÅ +œÂic$F
boÄp‘hìj`E¦Ñ°ˆ‚ ÛñeÙ€u–ø¤vøñmÀÁ¯QI@#"[geœÎC´áüf	õĞk4ß&¡	\"Hl˜²Q¤Æ´Féíİ ñYZ86$¹4!ä4ƒkÌ»ñ@náTØä7ªqœáNî€£wå¹Rp6Ô\ë¯€E—Æt±Z‚–® 60X€“Œªö h¨ƒ°yKˆ¸ŒF"jWÔ(@ÜüÅÆ}0k¬™7Şh5"Ñnü@ÓÆ¨±mÃt)ØË!ø 1ƒ],ÊX5ª—;î,›…uC›&t9‚©ÛnbÛ€é6ô—1!MgÕĞcÛ’	µÂºVÜø*È¯ñ¡¾ñB~á°‚êI}ãŒk#âÂ›@F‡ÛcŒS£q)À»‘O#ğQ6¨é°#=(bál|àm³oø.RÜÚÌ€(¾* Ó:Áüfüùˆ¨n$SÓ°Ã!XDC†^ Òt±#µ‘Á³ñæİÈĞØ€O}#.D€ ò‰áoC¾†2äŠ(5†zcÎ¼áÂ¢ È›†CcÖFİ@Lhaj0„iQôN_qº€’&I}¢P(úÒHàc;ÁHGk¼‰ –c7ÑHGkÜ	Gcìñ&m,: Ã+	&Nêc;á¨c;şÄ×Ç¹4c3şD]…A&Ùaœ_Q”&é¯ˆrÔê®­OWTùtkİ6Z•ñÜÙPD9j¿Š
LW†ñ5º˜ÀäŒmTÌ&VÄ€³É`âkc3şD£9Î=ş„c?Rå6Á8ãŒ7ÑX;ş˜M<úØãŒ7ñ˜c5şDc3Á¨àƒAğø£1ş„t?Î¨xÁ¨x¥pôQñ¯ÚDc7*Qšx¬	Ç€d	Æ6[ĞÉÊ>6Gåpt®Y&­Õ¹^&—z4÷ÔİÛh4
vo£qÈÍ-ÜÑyÒ4áXä—Ÿ”R İ[^yôhâqxC?İ5
‹àÁx|²¤HAJ²Q&ŸoQø•j\ş©•—ô'‡ÊÔİÛhÂ1¨JC5àæ?çÑ©Ëme
{u’ÁĞ_pBÓIgƒ‘Â¡`w W5¯6’ÕÕ²O<*ÊY2®ª2“Ö:PB=ó,'ÜĞ¯zÒÛ€îAU n¯UP×p,Ó$Œj4şˆ(Hm£pÌ¡âŞê¸¥Nšk¯?RÜ³Ôx–ĞHñVŸuÅ3æ<ÑØøÉƒ l‹«Iƒrù‚.øğW«(Ô £UE}T¯‹LÁ²¯® ™ÉxAÕ¿+¸†×©j²SWm‡&ùIúkÑ¶²h\Mt®M'é¿µDãê¢s= ÄI•avFƒX6`¦VÎÉI6à´;ë¯VÊ4Íu<5&¢D–ŠU³>QY³ìš´ù”Ğ5ŠæÑŠdW(Ë¤$¥JŒoÎü”)ÿRAz)O# „ÊT>•Ù’–`%q2i »tê ‘3ƒ%RØ±˜‡¦LfGkAZ}5@§†è(«ş1Œ
ÀİZŒ«Ib–‹‚6Ëja#ßÎmu°“™4ˆ²rî¥r)Çlw9³Òî:—¢Ü$;ÛrÎu¯sûMH)Ó›Ü¼Éã·È-ĞmòdŞËÉ³ü®‘¯ÌoPÛ-^ô İá-óŸß¡¨ª+‰®Sò›”–àmÊÎw¯ñûş¿ı¤‹€ò½NÅo
øm´×¨üÁ¿%¢Lµ½ºŞê¬¹ÑÚ+¥6Ë«qD}ƒ¤ICn•ë4e™Ô §Änù-ÈÿNó^§å7iım¡¥-çîĞ._ZıNÿ/-˜€%Øå3¨^×áHsÎŞ‚«ÆwàÎ½ïoÂW£ÛğW)Õ½†`ù7€X·ÔßAèïuD~ÑßÒ¼×ş£ßBìwD”©¶×7X{ÕõVßàæ£Û—®»Úz7Şz|çêz×Ü|tûÒuW[ÿæ£Û—®»Úú7Şz|çêz«opóÁû7Ş^î0}÷ºj¿	‚l÷A¸ RĞP*İFí¨ï5ÿ¿…æï€äÌö:óßD«n£}î5ı‹ßùï ss¯£û› ømP€öz¿şoêw08¨÷:†¿	šlw0*bp—ìIÓ)ømp• ¸åw<E Şòº«Ì¸ñ-Ü¹¾	B`ºŠg7ğúM¼Kè>àQI‚sßÜ®AHÁø‰³;Îÿì:ı¿NP©nA¤ß‚¨Ì[û-‚@~‹?ğÊ'Tiw›0qı.Ä;á¥ê&i)“UAY+ÅD)S¢•‚¤EŒ|b‹İâ„„üîŸÚOÓdŞ$Q	ßfó[$õ;¤ErºAÊo’šÛMÒúM¶2o°û}öâd[7ÈÊÎaºÃQANò»É9·›\dŞ$[IÜ&§ßåZnÅî&¤ÒÜç^<ö¹âyiºf¿Ë³@ä—`·)€/qµë¼ƒBñ›Rùİ†Zj#h[7ù)x5%ªıáéT)Ïv‹ŠbU

*A*óHj‚eŞ†Œ|È¼ÛTe§ºw@ÓÜ¤Fæ-j³Å{›ºQ¯¼ºECö›4Òt—¦Cnï_`­q7a«%½|F2“:’ò­®UÙŞ}ÆÕ`^ƒ,²|Ğéf•¢[pP.zUC©°­n2\»Ô×pÌòÑ8ôRœs{°Ú850KVJ‚uv¢–¨MÆDË'¶‰“IÜ\
	%‰O`2\C¿tŒÛ«qêW9çqoƒU¹û%
B¾C!¸ ÛíP¯c*—&1oÃHy’Pù¬Zp•u3ÖYƒÕ•Úßn®³ş†Ğ
	ÕîîJI,ïæ¯Ê&û®AÒï®JJîšíiÙÙö®²KCºL2Şí•’Yşƒ•²—ÿ`F–=Ú˜C8)•î­Í¹¯sQğ*ÙJ›œ‚rU¦Üò _&EÙ’>£ª!6‡%{Ü~´&5¾”ÔHîchˆÔŞ UÕª¨9_€2¯íW^u¤«‡B	uÅj=Z¥ SA”e&UÆ¥ºì¢“ÚT*^Îl²qMÃuÃäµ¼;…yXğĞ…1<bIôÍ_“æbÚ¤˜5{£µ0—y‹Üî`Ùt¬úÃUYVë\Çf®ƒ©_·Ûì7±ë÷À\`QbØËÇ¡ÆI¬ıR°)óGk€]9"øÏí*áEp“e~“Èœï°*Ê-Ö©o¥L¯]ĞÄÌ=bD\–]Ôs6JÃp'¹g'7.ï¢X&ß¢PqÁÙ©É…d£¹ié´Eèigjg5à­*ÕV“ˆ.£ª!•h5 ~–IÕƒj1¬q—øT ¿gÇ:Ø²L8V‘¹Ì¤Îªú×YWçñŠLŠ¹«-ó ™ºûÄ–O\wƒÇRØÂµùœê¢n»J½‚×¦±Ó¤C.µ“*íNxjˆ@õ€(³‹D‘*¡ifª–”ĞT`¸:HdKºëoH÷ÈUùl(ä†Â$­•°´`xRU`ÉOúŒ³£’ÌJ,©ÑÜâui‘Okê¯-´ ×iËùÑj´7sı6Öø:¬Õ»Æ šˆÔà&¢2oé×ü[kt@Ö«
”ì¨œYÒªR\Š¡êôhMüªApyCx–D4©­¾.İ“œ™¤]µI/8ß S`QMÒ¡RAZ‹"T&lH®I’Vª¤•“ó’X¦ä—,	f×¤D–H2ª‚%¥Ì-ù÷WE»_cQP,ºSd°4Ämoã^ì[x^
vï¢Ütä¥!Li'ãU‰Èí"ó
eùI	†‚³-3“ZPå„*—ì\äVBIR%xoƒ×äæÑ:<ú}rå“—:”™t×¢@)~À+5…EéEâ*%yPªP–eOüJuÃ×à_ÄTrÁÕ*Q"W	'‰!üP$Ad˜©7@UùlIQF
våaœe·0?–{,Õ€ıàPìîl°>n2®Š{6ğço©ğ«&„'é®¿&şU#à–1qÖu¯àXkeŞ](±‘Ï17N2“R
;í©{¸ÑÆ+±]Awö`¥°-á©á ZY…rµ€”ÈUKO:ó`´ˆeC¼JP7ÉÉ Ì&-­ô‚_Št–VC¦?ZÙì—"÷«ãÖ@^DAj3„²Í’İIÏ#©‘‘ı™¹±Ï¹[Av²z·9è:Çl9åÌeo’=ä¤áŸ=Ræ"NF¯”–ß[)­}°ªPqşpuÚ²_‚¸’Î%w’¿¥äoX²·–ì-${#èDR"7‡Qíxv$ª’Ü˜WéHYÈOël0¾)İl¨ÁEI*AHV‹ã»Á)c“—3¯‚ò.µM"±–<, §Aß êI³æéÃôÚ¯&»ê&õ	Ù+HıÒP!Ù!ŸÕQk„yWœ^W¥ª3M5B³º,è0Ñ—?1€YiğWŒª’Y}Õ›ˆg6>Å¦x)É’Òjó/i¨ËNÃÀZm¤«…lÕ™Èd2À¯ZÒ\k7ZÕ3PW©q”Ohõ+¦ÕHZlµ2Ôf€3T Íw“ş†¯ŠyÕo®½îz«bQÄ·7\Ëê\*¢µm¸&Kğ*Ë"f	k–› e¬÷öºëo¸ñªØd¿¹İƒ© ]µ‹òx-ló¸]Á¯¹ˆ/K	=Zû<¯ŠCQŠÚ€Íµ×ßx°åv%‘6Z)åßXkUœŠ}kõ6Øh¥8Ï×GnàTÂ"ŠPû¢®½îúIõúº>^éµµ×½¿áÆĞ2¸ËÙ½6Z<E¹¹öºëo¸xs{°ñª¸–ÑŠÄ*#Bª>¦WñH²^PaÎ(‹ÊÂšs@aáf*Ì:òQğ, E‰ç@´!ÀV,«k€ÀmB€51¶:3 'DÔ,’–PIƒ8çã”Š|Ë:—¥E@ù” ëax ²HÔCæÃùÇnpäø^6€B ëU 7¾eÁzÚâèq¡¬5³†"À˜Ì(F'ä²’ÕAä7Aøª¿:A˜ªJud€/ØY¡9“ß„pª„o	Odš@&ó-Şâ	YLÈ•ßDˆêrE6!?°Õ¡f1|»–Ïø‡3@£ÃqáÁêJvààÁê
0G0ÖÆ `yªA8OŞ ¿	ÁË@@ÀÈO$Ef@dm`X"`¢à‡Êo" <¿	z	IF.Æ¾•cfÕ@F0>€°Q€Ø òuPN~~ƒ(ğ	á°:!(¾Cá[öŞ^~B8ü&Ou‘AP~„0‹å[È‚ùP¬Äê„@ªƒP º9àùh|Ş{€P¿	¢©Kgh¡E„YÀ,ï‡Äo ÈI~ÀU'BT;Àã7!ÜêD,¾Åê= 0ü&„R–ĞùM¯:HÕ‰Õ‰Ó''â«{ù,oR~‚°Uôê«ƒ\ru€euÀ²:ª‚­µ:äê@æ[$ßü Çy	xH2 1±ê X[X¡#*`Mˆ†oÉ}‚ü1å[:ßƒ4!~„¦:—cÙCä7!Ÿê T'„X lÕ	¡É¿‰Õ	R²î·ü†*øAæ7„ñ	AbÆG)\&v@z\ ][`.}ùMÄ’ˆòBªNDVr‚¸ò›!ßòÕä ËCbIÔÆùd`²{Œ¨eš¨¯€uéäµ¢ Ê#ÖÇ®Ê#ÌkE‘K;¯VS òñ–ó(Ï•³ÊÃSİÉ"b™7±P£*Uİ=D/½D¿‹Ä¥›Ä¶	w„O°L‘ĞÖÛ!Ù½LüÒÎkWšG’ø—ªòpòj›(&GÜ»‰[ù¬rÄ,+Ä¶r•‰ËÀe`Ü20ybŞWåáµbè¥­ºã]å'z\…šOR³LñZá]åá5¢LÀ,`Zé0àĞPšH Âo ïÜå$< )x±ÀsX{‚ÅfñN+	$	 V]¯öÑÊÙYê%ùÓ¥Xëƒ4a–»å¬¯åÑÆPí,İéš"ÇRƒVÃ•G'z /\¹6«Qaˆ´®´8‚¨Ï)İÊ¥C#=ÑÈ4Ñ Ö@îá[@ÙÛ’ªíJ)ĞW*®ò“ªhĞ!^+n¬“ÕÓ-ÄÒÄ½Í¶ƒı°]NuI“ûaÇ²„`BÏí&¥—í1 p›ÇÇàİ„±¶ÂgTáß’h*aïè'™=…DÔ©`îYNÊ‡‘Ú‰ÿœƒoaZ‹Ë!°1Š”í"æpp|Î¤wÃzU`àöäw§—nyçI–64åEuO¼ÍŞü‡KÄ¼Rp¾±ÚD…©ûJÃuZc¦6CAbóÏ½„0ë¥n]nCğrÂÔófË÷q^qx„æå…{îP­î#õeÄw=OQúŞÈåDlAìº²H´F^ÃÌD¹Ï30²“Üg‘•o™gÍ®ÆênÎ& rğNÚK!½,J5~½I:TzCR/›òL[bºW“i˜nŸå}êÕY}/ vıNÇF¹€şÚb>
ç†è†×ÚD7«•ÓAâ?ÏÒiûXŞ&{Ñî…y+’Eª‡j[QGQv\şÀs{3š]sæ­‘hœ+µÃck®Û qÂœSvà“éO:wR¾ŒèR·EÖÇà[ÆĞÕÅ'ÊµÁz‡á^ı!¤÷Ô'¹îän£İŸ·¨¼ —Qê†ôUÎÛ”Syé‡eÆ£”4ÉŸà¾“ù.¸–Y8Lê"âdueƒóã†JDúC³Ço¦ûaß’Û9À¾%YµÚ–¬{ktB¯·AV9Ä® 08©Â·ƒ˜gw¹p]€ı°í¤ nóÒa1Ùí„Jî8:ÖÎ¦6$„p¦hâ3«{ÆĞ<t±h4”[9=<ï{_Aä$§;à0‚ömÒl´`ƒö-q=Ä­Çj[¶l{Ó¼£(Ö:°™è.AÇ|•í'	İkª¼pİ.˜[^º¾q#Øê#¬âqùô¹^>å™-ßbâ¾@6¯¬ù&8|pi=j£pOÅaÔğ1ÛNò—áÜ×sÚ]{KL·#Ú\M¬Eôİ¢¯"£ª¢~±_>¶ÂmAæGáØXŒ˜4ÏµéZç‚¬—‚½…<ƒ­É3Rº*$ÈĞhÂ½Iud3ğL¥¢Û;Ñ†wCjO#`ºà=Èı""—–/Âóe¤æ¢Y:·	NrŞÇ†ôÎ.İßV<.Sèï Ûg`¾BHä÷$¼ú
ß–´‚«çà»Ã.DO5<ºxÊnøïœ­êŒ´hË
±_†i'ïÅK^jU)ší„¥U¦Í’&-mes|áEòp]A˜ÎTwë{ÑqKÁ¶ íCtÑœ¬t®“=jıåvÿ¢ÂÑDwóõFVvÄ;©jõ £û¸vùï´ïICŸˆ^>8ß×iá‰?XDà Ç‹¥%“KŒøRâIúÌãpç‹Û-iƒÁ¼ÄÉ¡a¿ılòErCfçàÖĞ–Ü^ÔA„nlbŞèìP M€·ÚÏtNÎ²ıcÛ[–NN3MÄ¯0üò¿ßÒ€ØiÆ§mm)q€0d@‡~qL^D2)K¶Ğ¦Ú&
Dxªù„&éË°ï$|zyä¼á+‡àû¸µ rZëÉ÷ ²[g¯2ƒÈB¼5Šˆø;ïãº'>ä2 ‡KÀx+§‡—T±u#ÑÄXb¶!D”œq7)aw6F|—â¹{½Ë°œ¦§pEtK~g›œªv=…hO-´ÏtKêçàg¿icQE{Û²}5’ÁÚ–£?9òãm9ÉAxºi*²¾ Ó†é$¶s"°ñƒ„÷r¿"0r{°iv3P.|ğvÇ"åËğ_)u”&õÓìd~
‰¼oy´6±gEâÎ8çÂâ ˆ~–«¶Î1«QÄ¿â;qâ¶ÌÁ"ÆÏ„µSoQğÎšåˆàDV+‘ö:Ík1£¬N¤r?æ¸ÒH.È{›’¤VÃëˆËœâv9a”‡Dê9 MbçÄd/Òw‰Ndš«³‰(Ò"îVuqesuäj­\ÙÕİ®©œ‹-uhUg5‘S|J·ÛÚ©öu
éSµhCæ.×™Â›pêãI—>#…ì‡‘ù€ka³¬›Kn(ì!^d
_ÅuT YKÁ¶väæ%äêÄykÃx·Ô	>b5rW©j ‘—D´:©Sü™Eîhx¦‘ßk§ÚGğiåÈn”hù­â:«YdOpv/Š=WgdP0¼878ßâÎwÕv‡ÆaZõTs…£¡é•q¯2›Ov2ÄgUDáËÈŸÚÒxP¼‹(½\=ªÌDát_ÎL¨./èğó‡ ’Bp¥ƒë¬ ŞV:¼® ø%mèQ>.ˆás_A
»Pß84ãY‘m¯tºU×JíMm$¦µcØÍ;Üº%”„®´ØÊ-Ÿ)J€Æ·Ô•ÅÙj»ç*UmåívVÛF:œ­3âà~'ÊËÊ—å·+@”4SBˆìdPÛ<ªU¯}¥âÚà4òæ<‚*û‘W•V*³ô)'0® xzÖÓC@¿JjâwÕå	Íë&¯ rù(êAÕ9P¹]ë·6zk‡ÇH§ep¿µ¥Ÿâ·×ö”QxØ:“BíFbQÿí¨ŞEŠX/'m=¨Şy"äÅ•1]‡äDz^:#—"#‘`…w$Æ…B"»•H¿¶jå´Èk%_Ûu«åGIj²`XF3CRòjlå">ÙP/(ßÌHŸÉ´ÆÚ[”V/ÂØæ¹E-Eén¥Í‡¾*šPã•IQOQ~ÂsgÔÀÌZ¾…³-¦,o0?- Bı¨®DU¢Èj7Û?¶½ñÚáEÍ’i‡)y;êMÕQ3„õWK5»Pßß9ÃÛ_;¼àı$êW¥‘™àYVÏTÏ¬bmõ+¯Z°¬`è+ÖÖRú²¨Ù€zè+[ "%vı¨Ò©Bm]ßS ùre|×64çqàèê}Ÿ0®N4d!åêß$ıà,À÷àXÕlLW^5]ÀáMõ:óJrùÉf˜a4¯Œk4NJ{I¹pîš§¾ùŒ!¥¯UŞt’wßÑÊË[SSx/Ö°y¾)¦K%úĞ¼ƒškhJ0Ëˆ,æwıQBkCYy{Íƒ²ÕkT¨Ë{ûÑú¨ ˆƒ%Uï./¹È6<óJ<J
)H#L¨?ı²­¡ÖJóCKˆ/»¾µ.ÁÑLLÔ¶ÆÊ8fåK__H!„éMÍøÍÅŞF9†4’T!pÍáK0Fd®ú¬¬}¥â:^·H ÏêihıòôïN÷]‚‡®¢õt?®İÍxáÓÓ4nù,);tÜGå@¾LI£»Kf$„pëè¹\£mÁİEC·cİƒÀWï¸úóRL•,ô Æ¬—Ø²	íè;ë…N|™(3!8Ôsğ>:»‡€^ W Bq<•:¸,;„>EÊUFïË-¨şpc=g4F+İUÏƒJèÏ  ¥:\– dç  úŒRBïddGúC ¿â¤.øVx{,fêÑÛ2×¦=X;<FĞ•7K!ÚL«Ü+1’ÕNMF `èMÒ´¤İBÂB©3÷Qp5g'J»Â²[#È™Ù¾ƒt%˜çqĞ¥‰Oã{©ü"Úï£ú=éæ-ˆ7qe4èú‰ì§i1üN›@—Œª÷dğ3Ø/›“öTÛh¶ø fJb¬äLÌ©œEÃ­ b¶cÙ½ ·b° =”Â0Œ@H˜T-·ËÏPòôW‚_ÁjAÅ;˜¾b´-hÿ…;•¤àra°0Wv¦?ÀØ†î^ÀÓôÿ¢ÓBëW–İlBv&!¬ŞV:<<åëI°öÅB<ãB·…¶ÛmØt;Úuv	ŠóFºÅ1:ìo‹-+t	ñƒà‚û‰Ø!ğ>ĞîppoyKÂ–Ğ‹=/]ßÂõEl–>öWnœäµĞ[E£;J†öƒ²»)XĞ¥ÄÁ{ˆü'œ .ÄÃä`ô#`Ú©ú I;So/_ŞGÛ<"azgè“8íÌ¿“ =wˆ
ñb=€~w`zğZùÉ¸¸‚ô·Óº3ıÅà¢ÄĞtz¨ØS˜™©Ø7“L"Ùã TúbòQÂˆ}‘Âo#à
¥æö
İ‡—î<z†W‘™“‘^À¿û1? úeü¯$s?ÉúI(;ÑaéRróƒŠ£¿Só,w~ç+]š‹£c,ô˜™äÆ¸‚lC ì^@ë_/ƒÍ@ÀH‡/ì˜«"ÚÂê)eî
m` `
ÓÕ“X¹/‘³¡¾ûÕ^,÷‡ğ¾lÌ¼‡‘€¡ÕÇ¸°¹Sù•Œyj@ûaŒæ>Z¡lñ„ÃDÆä*‚bÊò4é ˜?MÕ‰h÷b!‚àË¯™ÜQü"¥ú{3``Ë\€¨G·Äy.Úsæ–	@ÈÈd®‹Ç{rŸgnÃ|g÷ëÁú@øËÀo!'bz¯^$¬+¹†Rn¤ãì,~b-À$Uˆ¯çnrº%(š[¾Å­eZ1´,|›À¨…ö4¯LÜÕyW°X ôB/Ÿ-`6ÑpZ–éî–öèÉXç–pBAK/2Ñ½Øİq"O–{†YÓ^gXFÇ·ºß²€İ¶ĞCq> < oªIÕNÏèŞ Ús íH¼ŸÈÂ/EÄĞ;°İÑ8íİı6¯xÙ¬w¿q›JOfáÄşê‚úú7ö.>rEÃ!Z¤Cv	²“æßá/1;Ï®gHÒ"Ÿ úò‚sAÅgWŠÖ‘n×¼?xG™<-ˆi²l‘€hÊkã2ÎESu0ÚC¤š9ÁÉz™bŸ ‡åY ó;ßÛÒ¾EGƒe#^‰ç¶…â'Ê-àxGpmù*D;P¸J‚á²QŞB*Q§°çˆìvæÍgğ)’æ	L»q9;&ˆï‰@ç¸çÉ~¯¼LË¸õ#Mcûcx-z(®<ysK%éXşí´_eÂçb¹X;ßKôîú$M—;9SjÚ™Õ…å_ÆsGş]õ
ø;€-:ÀúÂÌ¡™şÄw„?NğŸ´.áHv2IÄ§qXĞ÷°ï,¾‹¡e2­màeÑ¤[T>@ıò—0İ©¡K)ì0iô -s,ªkgùËØ‘ø2c†ßµ{HêB: p4³)t;ñ{Y­6‚³g²=o†I‡'%^@}76É<‚yw‚TC•²(¸B9i\Šâ“^$Ôâq{Ğşˆ[#‚n'I1ëeØÚõJwj>KøKßÖ41×“Ñ ª±í Âèû•º“Ğxâ½`ä£8\^L(–†w6ÌXXDZXºKmĞk†Äë`æ=¤]N&ß;Qè>ÜºïÛ¦¦.2İCA·‚Rky'-ÆM,1§óQé#VŸğÙšÊ2%=ˆÏ\Ë·Ä«o«ƒ5Ç­Ç¤âª?Àô¦Ò3u'¾w41Ó´R®oX>ƒ¿9›D·šc®GÉï%1ƒ¶YÓ	½ã¥U’¥ıÄ|«×w$[€	¾.¶b”á.´U'a $§Lu_x* 3%à†•ö±°ê¥[f(Õ—¤˜,ÆAO— "ÍŠıó Ş0×sF/ŒßáÎŞ~¿Û‹ÇYb½œ™-àwghšK¨AC‘a´Í÷¨Õ ª÷`ôíx/=ìîŠè2.EÁ;ñø<Ø?Nñ‚¹÷—7Ìšb
Í.?JõF|gwüŸÕÉP/Øb¾%áı–(âŞÀÜ­àIO†!</CÜJgh:{ŞlÏ6>ìAuîVrk†/-ÔÍsg²ŒÎ%\Ä;©SV9Ñ}ØQî^&®—Ü¢Ôİf¦ )Å(¶=F“
ÖÑ	`íB˜õA[Ä:'A'k[ö¸ØÛÌñ¬å÷´ÒogîsàÛ_¢è²c2Ñİ9…ã(è¹ŠĞ°aªs¢g‰à»BéÇ˜Z öNº7Lö‚EŠLYÅ’æ0ÀA£Ü130rĞÿyÌ–P¥xL…ù·ã8/SW½ò`úğO{;³˜-¢=F­YGÈ–¡î2+„Ü‚> –¹Xx:şÎç*¨½¹´åEC|Ïbªä”fºŸğëGHŞŸÁ^y7¦»øíaT¼«|=G¦‘é]|Ï¹	wÈ¦$È†$q):ÅÒÀ»ÓûE|vº?ÌÔƒù©tKëKQqÙÉ?éëâãGA>•b˜ã™36ZO)îP1´ò;è[°øÊ®_ áÃÌœÈw&Ç	=¨ÿWˆ_‰ïÌ|Œ®+iÅßîb@7½Óª¦#œHv/ú=CØø°½2`XĞñEB/{jèû¹’/ıi{ùcô^ilæ°õFİI+;ÌÁ:ş 6'·Î	ÿ!PÔ¼¨­]
3°Şˆ0"¡b{Í”ìÇ­¬,¢m@û˜w„>ŠÅnÓê%”!GÂ`¥zRv9ˆ\ õj7Ìt¶ƒPÌ¾›Â¥ÇìªHäÏX9Ìºöò6tÎh¯€ê@åÃØ^9¬?AÎ<k—xB¼´¡¬´Ì'âİ¯¹¨§8h$\ïØ^ù$aW&¸ å8\ÑĞ‚ª/Ò{Eˆ™sªû )ïQSÒEø]bü“Œ|¥:@Ü®	Âo7hßCò¼@ŠPİ™z7ÍKY	‚à4-…ó hï"¹­vû»'ÙÖKEk*¢×­äIOhı}§Ñh¬=±)ËJàÚ4¶s‰½ÑNP+Jµ4JH¾ı*m·P·TwI3ô()8İÊœØ ŸÀd‡û¨¸–Pı$=_¦¡¸ãÒ}8›ÍXÊp?»âÚ±µúïCèÓ,n Ø9;» hò_ óÆ‚hvî úÜÀ×İÌôè¶ˆw)Š{t
ïÃmÑ%¼—Aw ùeúv›ILz®“ŸÉ‚±÷¿Cà}Ìnhèyt,rĞß^ËàMo4F"Ç+e±sF£S6ZºUéÉlhÎù'tÏ1¯ı`Ø¢Ø92]©>³Ü‘èPÕs4„ß…÷es to a stream, defer calls to `writable.uncork()` using`process.nextTick()`. Doing so allows batching of all`writable.write()` calls that occur within a given Node.js event
             * loop phase.
             *
             * ```js
             * stream.cork();
             * stream.write('some ');
             * stream.write('data ');
             * process.nextTick(() => stream.uncork());
             * ```
             *
             * If the `writable.cork()` method is called multiple times on a stream, the
             * same number of calls to `writable.uncork()` must be called to flush the buffered
             * data.
             *
             * ```js
             * stream.cork();
             * stream.write('some ');
             * stream.cork();
             * stream.write('data ');
             * process.nextTick(() => {
             *   stream.uncork();
             *   // The data will not be flushed until uncork() is called a second time.
             *   stream.uncork();
             * });
             * ```
             *
             * See also: `writable.cork()`.
             * @since v0.11.2
             */
            uncork(): void;
            /**
             * Destroy the stream. Optionally emit an `'error'` event, and emit a `'close'`event (unless `emitClose` is set to `false`). After this call, the writable
             * stream has ended and subsequent calls to `write()` or `end()` will result in
             * an `ERR_STREAM_DESTROYED` error.
             * This is a destructive and immediate way to destroy a stream. Previous calls to`write()` may not have drained, and may trigger an `ERR_STREAM_DESTROYED` error.
             * Use `end()` instead of destroy if data should flush before close, or wait for
             * the `'drain'` event before destroying the stream.
             *
             * Once `destroy()` has been called any further calls will be a no-op and no
             * further errors except from `_destroy()` may be emitted as `'error'`.
             *
             * Implementors should not override this method,
             * but instead implement `writable._destroy()`.
             * @since v8.0.0
             * @param error Optional, an error to emit with `'error'` event.
             */
            destroy(error?: Error): this;
            /**
             * Event emitter
             * The defined events on documents including:
             * 1. close
             * 2. drain
             * 3. error
             * 4. finish
             * 5. pipe
             * 6. unpipe
             */
            addListener(event: 'close', listener: () => void): this;
            addListener(event: 'drain', listener: () => void): this;
            addListener(event: 'error', listener: (err: Error) => void): this;
            addListener(event: 'finish', listener: () => void): this;
            addListener(event: 'pipe', listener: (src: Readable) => void): this;
            addListener(event: 'unpipe', listener: (src: Readable) => void): this;
            addListener(event: string | symbol, listener: (...args: any[]) => void): this;
            emit(event: 'close'): boolean;
            emit(event: 'drain'): boolean;
            emit(event: 'error', err: Error): boolean;
            emit(event: 'finish'): boolean;
            emit(event: 'pipe', src: Readable): boolean;
            emit(event: 'unpipe', src: Readable): boolean;
            emit(event: string | symbol, ...args: any[]): boolean;
            on(event: 'close', listener: () => void): this;
            on(event: 'drain', listener: () => void): this;
            on(event: 'error', listener: (err: Error) => void): this;
            on(event: 'finish', listener: () => void): this;
            on(event: 'pipe', listener: (src: Readable) => void): this;
            on(event: 'unpipe', listener: (src: Readable) => void): this;
            on(event: string | symbol, listener: (...args: any[]) => void): this;
            once(event: 'close', listener: () => void): this;
            once(event: 'drain', listener: () => void): this;
            once(event: 'error', listener: (err: Error) => void): this;
            once(event: 'finish', listener: () => void): this;
            once(event: 'pipe', listener: (src: Readable) => void): this;
            once(event: 'unpipe', listener: (src: Readable) => void): this;
            once(event: string | symbol, listener: (...args: any[]) => void): this;
            prependListener(event: 'close', listener: () => void): this;
            prependListener(event: 'drain', listener: () => void): this;
            prependListener(event: 'error', listener: (err: Error) => void): this;
            prependListener(event: 'finish', listener: () => void): this;
            prependListener(event: 'pipe', listener: (src: Readable) => void): this;
            prependListener(event: 'unpipe', listener: (src: Readable) => void): this;
            prependListener(event: string | symbol, listener: (...args: any[]) => void): this;
            prependOnceListener(event: 'close', listener: () => void): this;
            prependOnceListener(event: 'drain', listener: () => void): this;
            prependOnceListener(event: 'error', listener: (err: Error) => void): this;
            prependOnceListener(event: 'finish', listener: () => void): this;
            prependOnceListener(event: 'pipe', listener: (src: Readable) => void): this;
            prependOnceListener(event: 'unpipe', listener: (src: Readable) => void): this;
            prependOnceListener(event: string | symbol, listener: (...args: any[]) => void): this;
            removeListener(event: 'close', listener: () => void): this;
            removeListener(event: 'drain', listener: () => void): this;
            removeListener(event: 'error', listener: (err: Error) => void): this;
            removeListener(event: 'finish', listener: () => void): this;
            removeListener(event: 'pipe', listener: (src: Readable) => void): this;
            removeListener(event: 'unpipe', listener: (src: Readable) => void): this;
            removeListener(event: string | symbol, listener: (...args: any[]) => void): this;
        }
        interface DuplexOptions extends ReadableOptions, WritableOptions {
            allowHalfOpen?: boolean | undefined;
            readableObjectMode?: boolean | undefined;
            writableObjectMode?: boolean | undefined;
            readableHighWaterMark?: number | undefined;
            writableHighWaterMark?: number | undefined;
            writableCorked?: number | undefined;
            construct?(this: Duplex, callback: (error?: Error | null) => void): void;
            read?(this: Duplex, size: number): void;
            write?(this: Duplex, chunk: any, encoding: BufferEncoding, callback: (error?: Error | null) => void): void;
            writev?(
                this: Duplex,
                chunks: Array<{
                    chunk: any;
                    encoding: BufferEncoding;
                }>,
                callback: (error?: Error | null) => void
            ): void;
            final?(this: Duplex, callback: (error?: Error | null) => void): void;
            destroy?(this: Duplex, error: Error | null, callback: (error: Error | null) => void): void;
        }
        /**
         * Duplex streams are streams that implement both the `Readable` and `Writable` interfaces.
         *
         * Examples of `Duplex` streams include:
         *
         * * `TCP sockets`
         * * `zlib streams`
         * * `crypto streams`
         * @since v0.9.4
         */
        class Duplex extends Readable implements Writable {
            readonly writable: boolean;
            readonly writableEnded: boolean;
            readonly writableFinished: boolean;
            readonly writableHighWaterMark: number;
            readonly writableLength: number;
            readonly writableObjectMode: boolean;
            readonly writableCorked: number;
            readonly writableNeedDrain: boolean;
            readonly closed: boolean;
            readonly errored: Error | null;
            /**
             * If `false` then the stream will automatically end the writable side when the
             * readable side ends. Set initially by the `allowHalfOpen` constructor option,
             * which defaults to `false`.
             *
             * This can be changed manually to change the half-open behavior of an existing`Duplex` stream instance, but must be changed before the `'end'` event is
             * emitted.
             * @since v0.9.4
             */
            allowHalfOpen: boolean;
            constructor(opts?: DuplexOptions);
            /**
             * A utility method for creating duplex streams.
             *
             * - `Stream` converts writable stream into writable `Duplex` and readable stream
             *   to `Duplex`.
             * - `Blob` converts into readable `Duplex`.
             * - `string` converts into readable `Duplex`.
             * - `ArrayBuffer` converts into readable `Duplex`.
             * - `AsyncIterable` converts into a readable `Duplex`. Cannot yield `null`.
             * - `AsyncGeneratorFunction` converts into a readable/writable transform
             *   `Duplex`. Must take a source `AsyncIterable` as first parameter. Cannot yield
             *   `null`.
             * - `AsyncFunction` converts into a writable `Duplex`. Must return
             *   either `null` or `undefined`
             * - `Object ({ writable, readable })` converts `readable` and
             *   `writable` into `Stream` and then combines them into `Duplex` where the
             *   `Duplex` will write to the `writable` and read from the `readable`.
             * - `Promise` converts into readable `Duplex`. Value `null` is ignored.
             *
             * @since v16.8.0
             */
            static from(src: Stream | NodeBlob | ArrayBuffer | string | Iterable<any> | AsyncIterable<any> | AsyncGeneratorFunction | Promise<any> | Object): Duplex;
            _write(chunk: any, encoding: BufferEncoding, callback: (error?: Error | null) => void): void;
            _writev?(
                chunks: Array<{
                    chunk: any;
                    encoding: BufferEncoding;
                }>,
                callback: (error?: Error | null) => void
            ): void;
            _destroy(error: Error | null, callback: (error: Error | null) => void): void;
            _final(callback: (error?: Error | null) => void): void;
            write(chunk: any, encoding?: BufferEncoding, cb?: (error: Error | null | undefined) => void): boolean;
            write(chunk: any, cb?: (error: Error | null | undefined) => void): boolean;
            setDefaultEncoding(encoding: BufferEncoding): this;
            end(cb?: () => void): this;
            end(chunk: any, cb?: () => void): this;
            end(chunk: any, encoding?: BufferEncoding, cb?: () => void): this;
            cork(): void;
            uncork(): void;
        }
        type TransformCallback = (error?: Error | null, data?: any) => void;
        interface TransformOptions extends DuplexOptions {
            construct?(this: Transform, callback: (error?: Error | null) => void): void;
            read?(this: Transform, size: number): void;
            write?(this: Transform, chunk: any, encoding: BufferEncoding, callback: (error?: Error | null) => void): void;
            writev?(
                this: Transform,
                chunks: Array<{
                    chunk: any;
                    encoding: BufferEncoding;
                }>,
                callback: (error?: Error | null) => void
            ): void;
            final?(this: Transform, callback: (error?: Error | null) => void): void;
            destroy?(this: Transform, error: Error | null, callback: (error: Error | null) => void): void;
            transform?(this: Transform, chunk: any, encoding: BufferEncoding, callback: TransformCallback): void;
            flush?(this: Transform, callback: TransformCallback): void;
        }
        /**
         * Transform streams are `Duplex` streams where the output is in some way
         * related to the input. Like all `Duplex` streams, `Transform` streams
         * implement both the `Readable` and `Writable` interfaces.
         *
         * Examples of `Transform` streams include:
         *
         * * `zlib streams`
         * * `crypto streams`
         * @since v0.9.4
         */
        class Transform extends Duplex {
            constructor(opts?: TransformOptions);
            _transform(chunk: any, encoding: BufferEncoding, callback: TransformCallback): void;
            _flush(callback: TransformCallback): void;
        }
        /**
         * The `stream.PassThrough` class is a trivial implementation of a `Transform` stream that simply passes the input bytes across to the output. Its purpose is
         * primarily for examples and testing, but there are some use cases where`stream.PassThrough` is useful as a building block for novel sorts of streams.
         */
        class PassThrough extends Transform {}
        /**
         * Attaches an AbortSignal to a readable or writeable stream. This lets code
         * control stream destruction using an `AbortController`.
         *
         * Calling `abort` on the `AbortController` corresponding to the passed`AbortSignal` will behave the same way as calling `.destroy(new AbortError())`on the stream.
         *
         * ```js
         * const fs = require('fs');
         *
         * const controller = new AbortController();
         * const read = addAbortSignal(
         *   controller.signal,
         *   fs.createReadStream(('object.json'))
         * );
         * // Later, abort the operation closing the stream
         * controller.abort();
         * ```
         *
         * Or using an `AbortSignal` with a readable stream as an async iterable:
         *
         * ```js
         * const controller = new AbortController();
         * setTimeout(() => controller.abort(), 10_000); // set a timeout
         * const stream = addAbortSignal(
         *   controller.signal,
         *   fs.createReadStream(('object.json'))
         * );
         * (async () => {
         *   try {
         *     for await (const chunk of stream) {
         *       await process(chunk);
         *     }
         *   } catch (e) {
         *     if (e.name === 'AbortError') {
         *       // The operation was cancelled
         *     } else {
         *       throw e;
         *     }
         *   }
         * })();
         * ```
         * @since v15.4.0
         * @param signal A signal representing possible cancellation
         * @param stream a stream to attach a signal to
         */
        function addAbortSignal<T extends Stream>(signal: AbortSignal, stream: T): T;
        interface FinishedOptions extends Abortable {
            error?: boolean | undefined;
            readable?: boolean | undefined;
            writable?: boolean | undefined;
        }
        /**
         * A function to get notified when a stream is no longer readable, writable
         * or has experienced an error or a premature close event.
         *
         * ```js
         * const { finished } = require('stream');
         *
         * const rs = fs.createReadStream('archive.tar');
         *
         * finished(rs, (err) => {
         *   if (err) {
         *     console.error('Stream failed.', err);
         *   } else {
         *     console.log('Stream is done reading.');
         *   }
         * });
         *
         * rs.resume(); // Drain the stream.
         * ```
         *
         * Especially useful in error handling scenarios where a stream is destroyed
         * prematurely (like an aborted HTTP request), and will not emit `'end'`or `'finish'`.
         *
         * The `finished` API provides promise version:
         *
         * ```js
         * const { finished } = require('stream/promises');
         *
         * const rs = fs.createReadStream('archive.tar');
         *
         * async function run() {
         *   await finished(rs);
         *   console.log('Stream is done reading.');
         * }
         *
         * run().catch(console.error);
         * rs.resume(); // Drain the stream.
         * ```
         *
         * `stream.finished()` leaves dangling event listeners (in particular`'error'`, `'end'`, `'finish'` and `'close'`) after `callback` has been
         * invoked. The reason for this is so that unexpected `'error'` events (due to
         * incorrect stream implementations) do not cause unexpected crashes.
         * If this is unwanted behavior then the returned cleanup function needs to be
         * invoked in the callback:
         *
         * ```js
         * const cleanup = finished(rs, (err) => {
         *   cleanup();
         *   // ...
         * });
         * ```
         * @since v10.0.0
         * @param stream A readable and/or writable stream.
         * @param callback A callback function that takes an optional error argument.
         * @return A cleanup function which removes all registered listeners.
         */
        function finished(stream: NodeJS.ReadableStream | NodeJS.WritableStream | NodeJS.ReadWriteStream, options: FinishedOptions, callback: (err?: NodeJS.ErrnoException | null) => void): () => void;
        function finished(stream: NodeJS.ReadableStream | NodeJS.WritableStream | NodeJS.ReadWriteStream, callback: (err?: NodeJS.ErrnoException | null) => void): () => void;
        namespace finished {
            function __promisify__(stream: NodeJS.ReadableStream | NodeJS.WritableStream | NodeJS.ReadWriteStream, options?: FinishedOptions): Promise<void>;
        }
        type PipelineSourceFunction<T> = () => Iterable<T> | AsyncIterable<T>;
        type PipelineSource<T> = Iterable<T> | AsyncIterable<T> | NodeJS.ReadableStream | PipelineSourceFunction<T>;
        type PipelineTransform<S extends PipelineTransformSource<any>, U> =
            | NodeJS.ReadWriteStream
            | ((source: S extends (...args: any[]) => Iterable<infer ST> | AsyncIterable<infer ST> ? AsyncIterable<ST> : S) => AsyncIterable<U>);
        type PipelineTransformSource<T> = PipelineSource<T> | PipelineTransform<any, T>;
        type PipelineDestinationIterableFunction<T> = (source: AsyncIterable<T>) => AsyncIterable<any>;
        type PipelineDestinationPromiseFunction<T, P> = (source: AsyncIterable<T>) => Promise<P>;
        type PipelineDestination<S extends PipelineTransformSource<any>, P> = S extends PipelineTransformSource<infer ST>
            ? NodeJS.WritableStream | PipelineDestinationIterableFunction<ST> | PipelineDestinationPromiseFunction<ST, P>
            : never;
        type PipelineCallback<S extends PipelineDestination<any, any>> = S extends PipelineDestinationPromiseFunction<any, infer P>
            ? (err: NodeJS.ErrnoException | null, value: P) => void
            : (err: NodeJS.ErrnoException | null) => void;
        type PipelinePromise<S extends PipelineDestination<any, any>> = S extends PipelineDestinationPromiseFunction<any, infer P> ? Promise<P> : Promise<void>;
        interface PipelineOptions {
            signal: AbortSignal;
        }
        /**
         * A module method to pipe between streams and generators forwarding errors and
         * properly cleaning up and provide a callback when the pipeline is complete.
         *
         * ```js
         * const { pipeline } = require('stream');
         * const fs = require('fs');
         * const zlib = require('zlib');
         *
         * // Use the pipeline API to easily pipe a series of streams
         * // together and get notified when the pipeline is fully done.
         *
         * // A pipeline to gzip a potentially huge tar file efficiently:
         *
         * pipeline(
         *   fs.createReadStream('archive.tar'),
         *   zlib.createGzip(),
         *   fs.createWriteStream('archive.tar.gz'),
         *   (err) => {
         *     if (err) {
         *       console.error('Pipeline failed.', err);
         *     } else {
         *       console.log('Pipeline succeeded.');
         *     }
         *   }
         * );
         * ```
         *
         * The `pipeline` API provides a promise version, which can also
         * receive an options argument as the last parameter with a`signal` `AbortSignal` property. When the signal is aborted,`destroy` will be called on the underlying pipeline, with
         * an`AbortError`.
         *
         * ```js
         * const { pipeline } = require('stream/promises');
         *
         * async function run() {
         *   await pipeline(
         *     fs.createReadStream('archive.tar'),
         *     zlib.createGzip(),
         *     fs.createWriteStream('archive.tar.gz')
         *   );
         *   console.log('Pipeline succeeded.');
         * }
         *
         * run().catch(console.error);
         * ```
         *
         * To use an `AbortSignal`, pass it inside an options object,
         * as the last argument:
         *
         * ```js
         * const { pipeline } = require('stream/promises');
         *
         * async function run() {
         *   const ac = new AbortController();
         *   const signal = ac.signal;
         *
         *   setTimeout(() => ac.abort(), 1);
         *   await pipeline(
         *     fs.createReadStream('archive.tar'),
         *     zlib.createGzip(),
         *     fs.createWriteStream('archive.tar.gz'),
         *     { signal },
         *   );
         * }
         *
         * run().catch(console.error); // AbortError
         * ```
         *
         * The `pipeline` API also supports async generators:
         *
         * ```js
         * const { pipeline } = require('stream/promises');
         * const fs = require('fs');
         *
         * async function run() {
         *   await pipeline(
         *     fs.createReadStream('lowercase.txt'),
         *     async function* (source, { signal }) {
         *       source.setEncoding('utf8');  // Work with strings rather than `Buffer`s.
         *       for await (const chunk of source) {
         *         yield await processChunk(chunk, { signal });
         *       }
         *     },
         *     fs.createWriteStream('uppercase.txt')
         *   );
         *   console.log('Pipeline succeeded.');
         * }
         *
         * run().catch(console.error);
         * ```
         *
         * Remember to handle the `signal` argument passed into the async generator.
         * Especially in the case where the async generator is the source for the
         * pipeline (i.e. first argument) or the pipeline will never complete.
         *
         * ```js
         * const { pipeline } = require('stream/promises');
         * const fs = require('fs');
         *
         * async function run() {
         *   await pipeline(
         *     async function* ({ signal }) {
         *       await someLongRunningfn({ signal });
         *       yield 'asd';
         *     },
         *     fs.createWriteStream('uppercase.txt')
         *   );
         *   console.log('Pipeline succeeded.');
         * }
         *
         * run().catch(console.error);
         * ```
         *
         * `stream.pipeline()` will call `stream.destroy(err)` on all streams except:
         *
         * * `Readable` streams which have emitted `'end'` or `'close'`.
         * * `Writable` streams which have emitted `'finish'` or `'close'`.
         *
         * `stream.pipeline()` leaves dangling event listeners on the streams
         * after the `callback` has been invoked. In the case of reuse of streams after
         * failure, this can cause event listener leaks and swallowed errors. If the last
         * stream is readable, dangling event listeners will be removed so that the last
         * stream can be consumed later.
         *
         * `stream.pipeline()` closes all the streams when an error is raised.
         * The `IncomingRequest` usage with `pipeline` could lead to an unexpected behavior
         * once it would destroy the socket without sending the expected response.
         * See the example below:
         *
         * ```js
         * const fs = require('fs');
         * const http = require('http');
         * const { pipeline } = require('stream');
         *
         * const server = http.createServer((req, res) => {
         *   const fileStream = fs.createReadStream('./fileNotExist.txt');
         *   pipeline(fileStream, res, (err) => {
         *     if (err) {
         *       console.log(err); // No such file
         *       // this message can't be sent once `pipeline` already destroyed the socket
         *       return res.end('error!!!');
         *     }
         *   });
         * });
         * ```
         * @since v10.0.0
         * @param callback Called when the pipeline is fully done.
         */
        function pipeline<A extends PipelineSource<any>, B extends PipelineDestination<A, any>>(
            source: A,
            destination: B,
            callback?: PipelineCallback<B>
        ): B extends NodeJS.WritableStream ? B : NodeJS.WritableStream;
        function pipeline<A extends PipelineSource<any>, T1 extends PipelineTransform<A, any>, B extends PipelineDestination<T1, any>>(
            source: A,
            transform1: T1,
            destination: B,
            callback?: PipelineCallback<B>
        ): B extends NodeJS.WritableStream ? B : NodeJS.WritableStream;
        function pipeline<A extends PipelineSource<any>, T1 extends PipelineTransform<A, any>, T2 extends PipelineTransform<T1, any>, B extends PipelineDestination<T2, any>>(
            source: A,
            transform1: T1,
            transform2: T2,
            destination: B,
            callback?: PipelineCallback<B>
        ): B extends NodeJS.WritableStream ? B : NodeJS.WritableStream;
        function pipeline<
            A extends PipelineSource<any>,
            T1 extends PipelineTransform<A, any>,
            T2 extends PipelineTransform<T1, any>,
            T3 extends PipelineTransform<T2, any>,
            B extends PipelineDestination<T3, any>
        >(source: A, transform1: T1, transform2: T2, transform3: T3, destination: B, callback?: PipelineCallback<B>): B extends NodeJS.WritableStream ? B : NodeJS.WritableStream;
        function pipeline<
            A extends PipelineSource<any>,
            T1 extends PipelineTransform<A, any>,
            T2 extends PipelineTransform<T1, any>,
            T3 extends PipelineTransform<T2, any>,
            T4 extends PipelineTransform<T3, any>,
            B extends PipelineDestination<T4, any>
        >(source: A, transform1: T1, transform2: T2, transform3: T3, transform4: T4, destination: B, callback?: PipelineCallback<B>): B extends NodeJS.WritableStream ? B : NodeJS.WritableStream;
        function pipeline(
            streams: ReadonlyArray<NodeJS.ReadableStream | NodeJS.WritableStream | NodeJS.ReadWriteStream>,
            callback?: (err: NodeJS.ErrnoException | null) => void
        ): NodeJS.WritableStream;
        function pipeline(
            stream1: NodeJS.ReadableStream,
            stream2: NodeJS.ReadWriteStream | NodeJS.WritableStream,
            ...streams: Array<NodeJS.ReadWriteStream | NodeJS.WritableStream | ((err: NodeJS.ErrnoException | null) => void)>
        ): NodeJS.WritableStream;
        namespace pipeline {
            function __promisify__<A extends PipelineSource<any>, B extends PipelineDestination<A, any>>(source: A, destination: B, options?: PipelineOptions): PipelinePromise<B>;
            function __promisify__<A extends PipelineSource<any>, T1 extends PipelineTransform<A, any>, B extends PipelineDestination<T1, any>>(
                source: A,
                transform1: T1,
                destination: B,
                options?: PipelineOptions
            ): PipelinePromise<B>;
            function __promisify__<A extends PipelineSource<any>, T1 extends PipelineTransform<A, any>, T2 extends PipelineTransform<T1, any>, B extends PipelineDestination<T2, any>>(
                source: A,
                transform1: T1,
                transform2: T2,
                destination: B,
                options?: PipelineOptions
            ): PipelinePromise<B>;
            function __promisify__<
                A extends PipelineSource<any>,
                T1 extends PipelineTransform<A, any>,
                T2 extends PipelineTransform<T1, any>,
                T3 extends PipelineTransform<T2, any>,
                B extends PipelineDestination<T3, any>
            >(source: A, transform1: T1, transform2: T2, transform3: T3, destination: B, options?: PipelineOptions): PipelinePromise<B>;
            function __promisify__<
                A extends PipelineSource<any>,
                T1 extends PipelineTransform<A, any>,
                T2 extends PipelineTransform<T1, any>,
                T3 extends PipelineTransform<T2, any>,
                T4 extends PipelineTransform<T3, any>,
                B extends PipelineDestination<T4, any>
            >(source: A, transform1: T1, transform2: T2, transform3: T3, transform4: T4, destination: B, options?: PipelineOptions): PipelinePromise<B>;
            function __promisify__(streams: ReadonlyArray<NodeJS.ReadableStream | NodeJS.WritableStream | NodeJS.ReadWriteStream>, options?: PipelineOptions): Promise<void>;
            function __promisify__(
                stream1: NodeJS.ReadableStream,
                stream2: NodeJS.ReadWriteStream | NodeJS.WritableStream,
                ...streams: Array<NodeJS.ReadWriteStream | NodeJS.WritableStream | PipelineOptions>
            ): Promise<void>;
        }
        interface Pipe {
            close(): void;
            hasRef(): boolean;
            ref(): void;
            unref(): void;
        }

        /**
         * Returns whether the stream has encountered an error.
         * @since v17.3.0
         */
        function isErrored(stream: Readable | Writable | NodeJS.ReadableStream | NodeJS.WritableStream): boolean;

        /**
         * Returns whether the stream is readable.
         * @since v17.4.0
         */
        function isReadable(stream: Readable | NodeJS.ReadableStream): boolean;

        const promises: typeof streamPromises;
        const consumers: typeof streamConsumers;
    }
    export = internal;
}
declare module 'node:stream' {
    import stream = require('stream');
    export = stream;
}
